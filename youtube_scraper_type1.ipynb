{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "import json\n",
    "import socket\n",
    "import socks\n",
    "import requests\n",
    "import pickle\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_credentials(credentials,client_secrets_file):\n",
    "    scopes = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            credentials = pickle.load(token)    \n",
    "    #  Check if the credentials are invalid or do not exist \n",
    "    if not credentials or not credentials.valid:\n",
    "        # Check if the credentials have expired\n",
    "        if credentials and credentials.expired and credentials.refresh_token:\n",
    "            credentials.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(client_secrets_file, scopes)\n",
    "            credentials = flow.run_console()\n",
    "\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(credentials, token)\n",
    "    return credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(video_Id,credentials,api_service_name,api_version,searchTerms):\n",
    "    import googleapiclient.discovery\n",
    "    youtube = googleapiclient.discovery.build(api_service_name, api_version, credentials=credentials)\n",
    "    video_Id = video_Id\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet,replies\",\n",
    "        videoId=video_Id,\n",
    "        searchTerms=searchTerms,\n",
    "        maxResults = 100,\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    totalResults = 0\n",
    "    totalResults = int(response['pageInfo']['totalResults'])\n",
    "\n",
    "    count = 0\n",
    "    nextPageToken = ''\n",
    "    comments = []\n",
    "    first = True\n",
    "    further = True\n",
    "    while further:\n",
    "        halt = False\n",
    "        if first == False:\n",
    "            print('..')\n",
    "            try:\n",
    "                response = youtube.commentThreads().list(\n",
    "                    part=\"snippet,replies\",\n",
    "                    videoId=video_Id,\n",
    "                    searchTerms=searchTerms,\n",
    "                    maxResults = 100,\n",
    "                    textFormat='html',\n",
    "                    pageToken=nextPageToken\n",
    "                            ).execute()\n",
    "                totalResults = int(response['pageInfo']['totalResults'])\n",
    "            except HttpError as e:\n",
    "                print(\"An HTTP error %d occurred:\\n%s\" % (e.resp.status, e.content))\n",
    "                halt = True\n",
    "\n",
    "        if halt == False:\n",
    "            count += totalResults\n",
    "            for item in response[\"items\"]:\n",
    "                # è¿™åªæ˜¯ä¸€éƒ¨åˆ†æ•°æ®ï¼Œä½ éœ€è¦å•¥è‡ªå·±é€‰å°±è¡Œï¼Œå¯ä»¥å…ˆæ‰“å°ä¸‹ä½ èƒ½æ‹¿åˆ°é‚£äº›æ•°æ®ä¿¡æ¯ï¼ŒæŒ‰éœ€çˆ¬å–ã€‚\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"]\n",
    "                author = comment[\"snippet\"][\"authorDisplayName\"]\n",
    "                text = comment[\"snippet\"][\"textDisplay\"]\n",
    "                likeCount = comment[\"snippet\"]['likeCount']\n",
    "                publishtime = comment['snippet']['publishedAt']\n",
    "                comments.append([author, publishtime, likeCount, text,])\n",
    "\n",
    "#                 if int(item['snippet']['totalReplyCount']) >0:\n",
    "#                     parentID = item['id']\n",
    "#                     request2 = youtube.comments().list(part=\"snippet\",parentId= parentID,maxResults = 100)\n",
    "#                     response2 = request2.execute()\n",
    "#                     nextPageToken2 = ''\n",
    "#                     first2 = True\n",
    "#                     further2 = True   # æ˜¯å¦æŸ¥å®Œç¬¬ä¸€é¡µåè¿˜å¾€ä¸‹æŸ¥\n",
    "#                     totalResults2 = int(len(response2['items']))\n",
    "#                     while further2:\n",
    "#                         halt2 = False  #æ˜¯å¦ç»ˆæ­¢\n",
    "#                         if first2 == False:  #æ˜¯å¦æ˜¯å¾ªç¯çš„ç¬¬ä¸€æ¬¡\n",
    "#                             print('..')\n",
    "#                             try:\n",
    "#                                 response2 = youtube.comments().list(\n",
    "#                                     part=\"snippet\",\n",
    "#                                     maxResults = 100,\n",
    "#                                     textFormat='plainText',\n",
    "#                                     parentId = parentID,\n",
    "#                                     pageToken=nextPageToken2\n",
    "#                                             ).execute()\n",
    "#                                 totalResults2 = int(len(response2['items']))\n",
    "#                             except HttpError as e:\n",
    "#                                 print(\"An HTTP error %d occurred:\\n%s\" % (e.resp.status, e.content))\n",
    "#                                 halt2 = True\n",
    "\n",
    "#                         if halt2 == False:\n",
    "#                             for item2 in response2[\"items\"]:\n",
    "#                                 # è¿™åªæ˜¯ä¸€éƒ¨åˆ†æ•°æ®ï¼Œä½ éœ€è¦å•¥è‡ªå·±é€‰å°±è¡Œï¼Œå¯ä»¥å…ˆæ‰“å°ä¸‹ä½ èƒ½æ‹¿åˆ°é‚£äº›æ•°æ®ä¿¡æ¯ï¼ŒæŒ‰éœ€çˆ¬å–ã€‚\n",
    "#                                 author = item2[\"snippet\"][\"authorDisplayName\"]\n",
    "#                                 text = item2[\"snippet\"][\"textDisplay\"]\n",
    "#                                 likeCount = item2[\"snippet\"]['likeCount']\n",
    "#                                 publishtime = item2['snippet']['publishedAt']\n",
    "#                                 comments.append([author, publishtime, likeCount, text])\n",
    "#                             if totalResults2 < 100:\n",
    "#                                 further2 = False     #å¦‚æœè¿™ä¸€æ¬¡å¾ªç¯é‡Œçš„totalresultå°äº0åˆ™ï¼Œä¸è¿›è¡Œä¸‹ä¸€æ¬¡å¾ªç¯ï¼Œfurtherå°±ç­‰äºFalse\n",
    "#                                 first2 = False\n",
    "#                             else:\n",
    "#                                 further2 = True\n",
    "#                                 first2 = False\n",
    "#                                 try:\n",
    "#                                     nextPageToken2 = response2[\"nextPageToken\"]\n",
    "#                                 except KeyError as e:\n",
    "#                                     print(\"An KeyError error occurred: %s\" % (e))\n",
    "#                                     further2 = False               \n",
    "##############################################################################\n",
    "            if totalResults < 100:\n",
    "                further = False\n",
    "                first = False\n",
    "            else:\n",
    "                further = True\n",
    "                first = False\n",
    "                try:\n",
    "                    nextPageToken = response[\"nextPageToken\"]\n",
    "                except KeyError as e:\n",
    "                    print(\"An KeyError error occurred: %s\" % (e))\n",
    "                    further = False\n",
    "    print('get comment count: ', str(count))\n",
    "    ### write to csv file\n",
    "    data = np.array(comments)\n",
    "    print('total comments and replies: ',data.shape[0])\n",
    "    df = pd.DataFrame(data, columns=['author', 'publishtime', 'likeCount', 'comment',])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_format(df):\n",
    "    df['comment']=df['comment'].str.replace('&#39;','\\'')\n",
    "    df['comment']=df['comment'].str.replace('<br />',' ')   \n",
    "    df['comment']=df['comment'].str.replace('&quot','\" ')     \n",
    "    df = df[df['comment'].str.len()<=50]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(videoId_list,searchTerms):\n",
    "    #1.åˆå§‹åŒ–å˜é‡\n",
    "    scopes = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    client_secrets_file = \"client_secret.json\"    #è¿™ä¸ªjsonæ–‡ä»¶æ˜¯é€šè¿‡è°·æ­Œapiä¸‹è½½çš„    \n",
    "    credentials = None  \n",
    "    videoId_list = videoId_list\n",
    "    #2.å°†è°·æ­Œapiçš„å‡­æ®(credentials)è½¬æ¢ä¸ºpickleæ ¼å¼æ–‡ä»¶ï¼Œç„¶åä½¿ç”¨    \n",
    "    credentials = use_credentials(credentials,client_secrets_file)\n",
    "            \n",
    "    #3.\n",
    "    for video_id in videoId_list:\n",
    "        final_df = pd.DataFrame(columns=['author', 'publishtime', 'likeCount', 'comment'])\n",
    "        for term in searchTerms:\n",
    "            try:\n",
    "                df = pd.DataFrame(columns=['author', 'publishtime', 'likeCount', 'comment'])\n",
    "                df = get_comments(video_id,credentials,api_service_name,api_version,term)\n",
    "            except:\n",
    "                pass\n",
    "            #è¿™é‡Œéœ€è¦å¯¹dfè¿›è¡Œä¿®æ”¹\n",
    "            df = improve_format(df)            \n",
    "            final_df = final_df.append(df)\n",
    "        final_df.drop_duplicates(subset=['author', 'publishtime', 'likeCount', 'comment'],keep='first',inplace=True)       \n",
    "        output_filename = video_id+'_filter_searchTerms' +'_comments.csv'\n",
    "        final_df.to_csv(output_filename, index=0, encoding='utf_8_sig')#utf_8_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = ['CxwSs5-XizA']\n",
    "\n",
    "\n",
    "#  ['æ†¤æ€’','ğŸ˜¡','åœè¡—','æ„¤æ€’','ç”Ÿæ°”','ç”Ÿæ°£','å¥½æ°£','æ°£æ†¤']  angry\n",
    "#['å­æƒ¡','è¨å­','é„™è¦–','é„™è§†','åŒæ¶','ğŸ–•ğŸ¿','ğŸ¤®','é»‘è­¦']  disgusted\n",
    "#['å“­','éš¾è¿‡','ç—›å¿ƒ','ğŸ˜­','å¿ƒç—›','ğŸ˜¢','ğŸ’”','å‚·å¿ƒ']     sad\n",
    "#['å–„è‰¯']\n",
    "#['ğŸ˜¨'] fear\n",
    "searchTerms = ['ğŸ˜¢','å“­','éš¾è¿‡','é›£é','ç—›å¿ƒ','ğŸ˜­','å¿ƒç—›','å‚·å¿ƒ','æ“”å¿ƒ','æ“”æ†‚','æ‹…å¿§','å®³æ€•','ææ‡¼','é©šæ','æ“”é©šå—æ€•','å“ˆå“ˆ','ğŸ˜¨','é«˜èˆˆ',\\\n",
    "               'é–‹å¿ƒ','æ†¤æ€’','ğŸ˜¡','åœè¡—','ç”Ÿæ°£','å¥½æ°£','æ°£æ†¤','å”‰','è¨å­','é„™è¦–']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get comment count:  3\n",
      "total comments and replies:  3\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  2\n",
      "total comments and replies:  2\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  5\n",
      "total comments and replies:  5\n",
      "get comment count:  3\n",
      "total comments and replies:  3\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  9\n",
      "total comments and replies:  9\n",
      "get comment count:  7\n",
      "total comments and replies:  7\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  2\n",
      "total comments and replies:  2\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  4\n",
      "total comments and replies:  4\n",
      "get comment count:  3\n",
      "total comments and replies:  3\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  9\n",
      "total comments and replies:  9\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n"
     ]
    }
   ],
   "source": [
    "scrap(video_list,searchTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
