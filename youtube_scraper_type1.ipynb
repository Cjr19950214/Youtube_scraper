{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "import json\n",
    "import socket\n",
    "import socks\n",
    "import requests\n",
    "import pickle\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_credentials(credentials,client_secrets_file):\n",
    "    scopes = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            credentials = pickle.load(token)    \n",
    "    #  Check if the credentials are invalid or do not exist \n",
    "    if not credentials or not credentials.valid:\n",
    "        # Check if the credentials have expired\n",
    "        if credentials and credentials.expired and credentials.refresh_token:\n",
    "            credentials.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(client_secrets_file, scopes)\n",
    "            credentials = flow.run_console()\n",
    "\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(credentials, token)\n",
    "    return credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(video_Id,credentials,api_service_name,api_version,searchTerms):\n",
    "    import googleapiclient.discovery\n",
    "    youtube = googleapiclient.discovery.build(api_service_name, api_version, credentials=credentials)\n",
    "    video_Id = video_Id\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet,replies\",\n",
    "        videoId=video_Id,\n",
    "        searchTerms=searchTerms,\n",
    "        maxResults = 100,\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    totalResults = 0\n",
    "    totalResults = int(response['pageInfo']['totalResults'])\n",
    "\n",
    "    count = 0\n",
    "    nextPageToken = ''\n",
    "    comments = []\n",
    "    first = True\n",
    "    further = True\n",
    "    while further:\n",
    "        halt = False\n",
    "        if first == False:\n",
    "            print('..')\n",
    "            try:\n",
    "                response = youtube.commentThreads().list(\n",
    "                    part=\"snippet,replies\",\n",
    "                    videoId=video_Id,\n",
    "                    searchTerms=searchTerms,\n",
    "                    maxResults = 100,\n",
    "                    textFormat='html',\n",
    "                    pageToken=nextPageToken\n",
    "                            ).execute()\n",
    "                totalResults = int(response['pageInfo']['totalResults'])\n",
    "            except HttpError as e:\n",
    "                print(\"An HTTP error %d occurred:\\n%s\" % (e.resp.status, e.content))\n",
    "                halt = True\n",
    "\n",
    "        if halt == False:\n",
    "            count += totalResults\n",
    "            for item in response[\"items\"]:\n",
    "                # 这只是一部分数据，你需要啥自己选就行，可以先打印下你能拿到那些数据信息，按需爬取。\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"]\n",
    "                author = comment[\"snippet\"][\"authorDisplayName\"]\n",
    "                text = comment[\"snippet\"][\"textDisplay\"]\n",
    "                likeCount = comment[\"snippet\"]['likeCount']\n",
    "                publishtime = comment['snippet']['publishedAt']\n",
    "                comments.append([author, publishtime, likeCount, text,])\n",
    "\n",
    "#                 if int(item['snippet']['totalReplyCount']) >0:\n",
    "#                     parentID = item['id']\n",
    "#                     request2 = youtube.comments().list(part=\"snippet\",parentId= parentID,maxResults = 100)\n",
    "#                     response2 = request2.execute()\n",
    "#                     nextPageToken2 = ''\n",
    "#                     first2 = True\n",
    "#                     further2 = True   # 是否查完第一页后还往下查\n",
    "#                     totalResults2 = int(len(response2['items']))\n",
    "#                     while further2:\n",
    "#                         halt2 = False  #是否终止\n",
    "#                         if first2 == False:  #是否是循环的第一次\n",
    "#                             print('..')\n",
    "#                             try:\n",
    "#                                 response2 = youtube.comments().list(\n",
    "#                                     part=\"snippet\",\n",
    "#                                     maxResults = 100,\n",
    "#                                     textFormat='plainText',\n",
    "#                                     parentId = parentID,\n",
    "#                                     pageToken=nextPageToken2\n",
    "#                                             ).execute()\n",
    "#                                 totalResults2 = int(len(response2['items']))\n",
    "#                             except HttpError as e:\n",
    "#                                 print(\"An HTTP error %d occurred:\\n%s\" % (e.resp.status, e.content))\n",
    "#                                 halt2 = True\n",
    "\n",
    "#                         if halt2 == False:\n",
    "#                             for item2 in response2[\"items\"]:\n",
    "#                                 # 这只是一部分数据，你需要啥自己选就行，可以先打印下你能拿到那些数据信息，按需爬取。\n",
    "#                                 author = item2[\"snippet\"][\"authorDisplayName\"]\n",
    "#                                 text = item2[\"snippet\"][\"textDisplay\"]\n",
    "#                                 likeCount = item2[\"snippet\"]['likeCount']\n",
    "#                                 publishtime = item2['snippet']['publishedAt']\n",
    "#                                 comments.append([author, publishtime, likeCount, text])\n",
    "#                             if totalResults2 < 100:\n",
    "#                                 further2 = False     #如果这一次循环里的totalresult小于0则，不进行下一次循环，further就等于False\n",
    "#                                 first2 = False\n",
    "#                             else:\n",
    "#                                 further2 = True\n",
    "#                                 first2 = False\n",
    "#                                 try:\n",
    "#                                     nextPageToken2 = response2[\"nextPageToken\"]\n",
    "#                                 except KeyError as e:\n",
    "#                                     print(\"An KeyError error occurred: %s\" % (e))\n",
    "#                                     further2 = False               \n",
    "##############################################################################\n",
    "            if totalResults < 100:\n",
    "                further = False\n",
    "                first = False\n",
    "            else:\n",
    "                further = True\n",
    "                first = False\n",
    "                try:\n",
    "                    nextPageToken = response[\"nextPageToken\"]\n",
    "                except KeyError as e:\n",
    "                    print(\"An KeyError error occurred: %s\" % (e))\n",
    "                    further = False\n",
    "    print('get comment count: ', str(count))\n",
    "    ### write to csv file\n",
    "    data = np.array(comments)\n",
    "    print('total comments and replies: ',data.shape[0])\n",
    "    df = pd.DataFrame(data, columns=['author', 'publishtime', 'likeCount', 'comment',])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_format(df):\n",
    "    df['comment']=df['comment'].str.replace('&#39;','\\'')\n",
    "    df['comment']=df['comment'].str.replace('<br />',' ')   \n",
    "    df['comment']=df['comment'].str.replace('&quot','\" ')     \n",
    "    df = df[df['comment'].str.len()<=50]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(videoId_list,searchTerms):\n",
    "    #1.初始化变量\n",
    "    scopes = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    client_secrets_file = \"client_secret.json\"    #这个json文件是通过谷歌api下载的    \n",
    "    credentials = None  \n",
    "    videoId_list = videoId_list\n",
    "    #2.将谷歌api的凭据(credentials)转换为pickle格式文件，然后使用    \n",
    "    credentials = use_credentials(credentials,client_secrets_file)\n",
    "            \n",
    "    #3.\n",
    "    for video_id in videoId_list:\n",
    "        final_df = pd.DataFrame(columns=['author', 'publishtime', 'likeCount', 'comment'])\n",
    "        for term in searchTerms:\n",
    "            try:\n",
    "                df = pd.DataFrame(columns=['author', 'publishtime', 'likeCount', 'comment'])\n",
    "                df = get_comments(video_id,credentials,api_service_name,api_version,term)\n",
    "            except:\n",
    "                pass\n",
    "            #这里需要对df进行修改\n",
    "            df = improve_format(df)            \n",
    "            final_df = final_df.append(df)\n",
    "        final_df.drop_duplicates(subset=['author', 'publishtime', 'likeCount', 'comment'],keep='first',inplace=True)       \n",
    "        output_filename = video_id+'_filter_searchTerms' +'_comments.csv'\n",
    "        final_df.to_csv(output_filename, index=0, encoding='utf_8_sig')#utf_8_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = ['CxwSs5-XizA']\n",
    "\n",
    "\n",
    "#  ['憤怒','😡','卜街','愤怒','生气','生氣','好氣','氣憤']  angry\n",
    "#['厭惡','討厭','鄙視','鄙视','厌恶','🖕🏿','🤮','黑警']  disgusted\n",
    "#['哭','难过','痛心','😭','心痛','😢','💔','傷心']     sad\n",
    "#['善良']\n",
    "#['😨'] fear\n",
    "searchTerms = ['😢','哭','难过','難過','痛心','😭','心痛','傷心','擔心','擔憂','担忧','害怕','恐懼','驚恐','擔驚受怕','哈哈','😨','高興',\\\n",
    "               '開心','憤怒','😡','卜街','生氣','好氣','氣憤','唉','討厭','鄙視']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get comment count:  3\n",
      "total comments and replies:  3\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  2\n",
      "total comments and replies:  2\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  5\n",
      "total comments and replies:  5\n",
      "get comment count:  3\n",
      "total comments and replies:  3\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  9\n",
      "total comments and replies:  9\n",
      "get comment count:  7\n",
      "total comments and replies:  7\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  2\n",
      "total comments and replies:  2\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  4\n",
      "total comments and replies:  4\n",
      "get comment count:  3\n",
      "total comments and replies:  3\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  9\n",
      "total comments and replies:  9\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n"
     ]
    }
   ],
   "source": [
    "scrap(video_list,searchTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
