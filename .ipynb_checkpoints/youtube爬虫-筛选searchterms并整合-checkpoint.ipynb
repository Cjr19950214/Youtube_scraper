{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import os\n",
    "import numpy as np\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "import json\n",
    "import socket\n",
    "import socks\n",
    "import requests\n",
    "import pickle\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_credentials(credentials,client_secrets_file):\n",
    "    \"\"\"use google credentials(client_secret.json)/\n",
    "    利用从谷歌api网站获取的client_secret.json文件，将其转换成pickle格式，/\n",
    "    下次使用爬虫时会判断是否有这个piclke文件，有的话就继续使用/\n",
    "    （使用证书的目的是每次爬虫运行不需要人工验证）\"\"\"\n",
    "    scopes = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            credentials = pickle.load(token)    \n",
    "    #  Check if the credentials are invalid or do not exist \n",
    "    if not credentials or not credentials.valid:\n",
    "        # Check if the credentials have expired\n",
    "        if credentials and credentials.expired and credentials.refresh_token:\n",
    "            credentials.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(client_secrets_file, scopes)\n",
    "            credentials = flow.run_console()\n",
    "\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(credentials, token)\n",
    "    return credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(video_Id,credentials,api_service_name,api_version):\n",
    "    \"\"\"获取评论，需要传入的参数：/\n",
    "    video_Id：YouTube视频Id号；credentials:谷歌api证书，从上一个use_credentials()获得/\n",
    "    api_service_name，api_version会在下面的scraper()中得到;\n",
    "    searchTerms：用于筛选评论的关键词，爬虫会爬取包含这些关键词的评论\"\"\"\n",
    "    import googleapiclient.discovery\n",
    "    youtube = googleapiclient.discovery.build(api_service_name, api_version, credentials=credentials)\n",
    "    video_Id = video_Id\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet,replies\",\n",
    "        videoId=video_Id,\n",
    "        #searchTerms=searchTerms,\n",
    "        maxResults = 100,\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    totalResults = 0\n",
    "    totalResults = int(response['pageInfo']['totalResults'])\n",
    "\n",
    "    count = 0\n",
    "    nextPageToken = ''\n",
    "    comments = []\n",
    "    first = True\n",
    "    further = True\n",
    "    while further:\n",
    "        halt = False\n",
    "        if first == False:\n",
    "            print('..')\n",
    "            try:\n",
    "                response = youtube.commentThreads().list(\n",
    "                    part=\"snippet,replies\",\n",
    "                    videoId=video_Id,\n",
    "                    searchTerms=searchTerms,\n",
    "                    maxResults = 100,\n",
    "                    textFormat='html',\n",
    "                    pageToken=nextPageToken\n",
    "                            ).execute()\n",
    "                totalResults = int(response['pageInfo']['totalResults'])\n",
    "            except HttpError as e:\n",
    "                print(\"An HTTP error %d occurred:\\n%s\" % (e.resp.status, e.content))\n",
    "                halt = True\n",
    "\n",
    "        if halt == False:\n",
    "            count += totalResults\n",
    "            for item in response[\"items\"]:\n",
    "                # 这只是一部分数据，你需要啥自己选就行，可以先打印下你能拿到那些数据信息，按需爬取。\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"]\n",
    "                author = comment[\"snippet\"][\"authorDisplayName\"]\n",
    "                text = comment[\"snippet\"][\"textDisplay\"]\n",
    "                likeCount = comment[\"snippet\"]['likeCount']\n",
    "                publishtime = comment['snippet']['publishedAt']\n",
    "                comments.append([author, publishtime, likeCount, text,])\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "                if int(item['snippet']['totalReplyCount']) >0:\n",
    "                    parentID = item['id']\n",
    "                    request2 = youtube.comments().list(part=\"snippet\",parentId= parentID,maxResults = 100)\n",
    "                    response2 = request2.execute()\n",
    "                    nextPageToken2 = ''\n",
    "                    first2 = True\n",
    "                    further2 = True   # 是否查完第一页后还往下查\n",
    "                    totalResults2 = int(len(response2['items']))\n",
    "                    while further2:\n",
    "                        halt2 = False  #是否终止\n",
    "                        if first2 == False:  #是否是循环的第一次\n",
    "                            print('..')\n",
    "                            try:\n",
    "                                response2 = youtube.comments().list(\n",
    "                                    part=\"snippet\",\n",
    "                                    maxResults = 100,\n",
    "                                    textFormat='plainText',\n",
    "                                    parentId = parentID,\n",
    "                                    pageToken=nextPageToken2\n",
    "                                            ).execute()\n",
    "                                totalResults2 = int(len(response2['items']))\n",
    "                            except HttpError as e:\n",
    "                                print(\"An HTTP error %d occurred:\\n%s\" % (e.resp.status, e.content))\n",
    "                                halt2 = True\n",
    "\n",
    "                        if halt2 == False:\n",
    "                            for item2 in response2[\"items\"]:\n",
    "                                # 这只是一部分数据，你需要啥自己选就行，可以先打印下你能拿到那些数据信息，按需爬取。\n",
    "                                author = item2[\"snippet\"][\"authorDisplayName\"]\n",
    "                                text = item2[\"snippet\"][\"textDisplay\"]\n",
    "                                likeCount = item2[\"snippet\"]['likeCount']\n",
    "                                publishtime = item2['snippet']['publishedAt']\n",
    "                                comments.append([author, publishtime, likeCount, text])\n",
    "                            if totalResults2 < 100:\n",
    "                                further2 = False     #如果这一次循环里的totalresult小于0则，不进行下一次循环，further就等于False\n",
    "                                first2 = False\n",
    "                            else:\n",
    "                                further2 = True\n",
    "                                first2 = False\n",
    "                                try:\n",
    "                                    nextPageToken2 = response2[\"nextPageToken\"]\n",
    "                                except KeyError as e:\n",
    "                                    print(\"An KeyError error occurred: %s\" % (e))\n",
    "                                    further2 = False               \n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "            if totalResults < 100:\n",
    "                further = False\n",
    "                first = False\n",
    "            else:\n",
    "                further = True\n",
    "                first = False\n",
    "                try:\n",
    "                    nextPageToken = response[\"nextPageToken\"]\n",
    "                except KeyError as e:\n",
    "                    print(\"An KeyError error occurred: %s\" % (e))\n",
    "                    further = False\n",
    "    print('get comment count: ', str(count))\n",
    "    ### write to csv file\n",
    "    data = np.array(comments)\n",
    "    print('total comments and replies: ',data.shape[0])\n",
    "    df = pd.DataFrame(data, columns=['author', 'publishtime', 'likeCount', 'comment',])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_format(df):\n",
    "    \"\"\"改善输出的格式\"\"\"\n",
    "    df['comment']=df['comment'].str.replace('&#39;','\\'')\n",
    "    df['comment']=df['comment'].str.replace('<br />',' ')   \n",
    "    df['comment']=df['comment'].str.replace('&quot','\" ')     \n",
    "    df = df[df['comment'].str.len()<=50]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(videoId_list):\n",
    "    #1.初始化变量\n",
    "    scopes = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    client_secrets_file = \"cici_client_secret.json\"    #这个json文件是通过谷歌api下载的    \n",
    "    credentials = None  \n",
    "    videoId_list = videoId_list\n",
    "    #2.将谷歌api的凭据(credentials)转换为pickle格式文件，然后使用    \n",
    "    credentials = use_credentials(credentials,client_secrets_file)\n",
    "            \n",
    "    #3.\n",
    "    for video_id in videoId_list:\n",
    "        df = get_comments(video_id,credentials,api_service_name,api_version)\n",
    "        #这里需要对df进行修改\n",
    "        df = improve_format(df)\n",
    "        output_filename = video_id + '_comments.csv'\n",
    "        df.to_csv(output_filename, index=0, encoding='utf_8_sig')#utf_8_sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = ['PlESWcaAHKk','vkWH92FhT3M','8NEl21QYDdI&t=312s','AFw6MqXAOJ8','B0_G9_MBRk4','ozf26RgCm1A','scnUloWsz2g&t=1s','ZEJUb4cThlM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get comment count:  4\n",
      "total comments and replies:  4\n",
      "get comment count:  42\n",
      "total comments and replies:  42\n",
      "get comment count:  4\n",
      "total comments and replies:  4\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  15\n",
      "total comments and replies:  15\n",
      "get comment count:  4\n",
      "total comments and replies:  4\n",
      "get comment count:  11\n",
      "total comments and replies:  11\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  42\n",
      "total comments and replies:  42\n",
      "get comment count:  28\n",
      "total comments and replies:  28\n",
      "get comment count:  21\n",
      "total comments and replies:  21\n",
      "get comment count:  97\n",
      "total comments and replies:  97\n",
      "get comment count:  73\n",
      "total comments and replies:  73\n",
      "get comment count:  2\n",
      "total comments and replies:  2\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n",
      "get comment count:  4\n",
      "total comments and replies:  4\n",
      "get comment count:  4\n",
      "total comments and replies:  4\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  14\n",
      "total comments and replies:  14\n",
      "get comment count:  3\n",
      "total comments and replies:  3\n",
      "get comment count:  12\n",
      "total comments and replies:  12\n",
      "get comment count:  3\n",
      "total comments and replies:  3\n",
      "get comment count:  14\n",
      "total comments and replies:  14\n",
      "get comment count:  8\n",
      "total comments and replies:  8\n",
      "get comment count:  3\n",
      "total comments and replies:  3\n",
      "get comment count:  64\n",
      "total comments and replies:  64\n",
      "get comment count:  73\n",
      "total comments and replies:  73\n",
      "get comment count:  1\n",
      "total comments and replies:  1\n",
      "get comment count:  0\n",
      "total comments and replies:  0\n"
     ]
    }
   ],
   "source": [
    "scrap(video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
