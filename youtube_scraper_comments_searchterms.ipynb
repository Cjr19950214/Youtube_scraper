{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import os\n",
    "import numpy as np\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "import json\n",
    "import socket\n",
    "import socks\n",
    "import requests\n",
    "import pickle\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_credentials(credentials,client_secrets_file):\n",
    "    \"\"\"use google credentials(client_secret.json)/\n",
    "    åˆ©ç”¨ä»è°·æ­Œapiç½‘ç«™è·å–çš„client_secret.jsonæ–‡ä»¶ï¼Œå°†å…¶è½¬æ¢æˆpickleæ ¼å¼ï¼Œ/\n",
    "    ä¸‹æ¬¡ä½¿ç”¨çˆ¬è™«æ—¶ä¼šåˆ¤æ–­æ˜¯å¦æœ‰è¿™ä¸ªpiclkeæ–‡ä»¶ï¼Œæœ‰çš„è¯å°±ç»§ç»­ä½¿ç”¨/\n",
    "    ï¼ˆä½¿ç”¨è¯ä¹¦çš„ç›®çš„æ˜¯æ¯æ¬¡çˆ¬è™«è¿è¡Œä¸éœ€è¦äººå·¥éªŒè¯ï¼‰\"\"\"\n",
    "    scopes = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            credentials = pickle.load(token)    \n",
    "    #  Check if the credentials are invalid or do not exist \n",
    "    if not credentials or not credentials.valid:\n",
    "        # Check if the credentials have expired\n",
    "        if credentials and credentials.expired and credentials.refresh_token:\n",
    "            credentials.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(client_secrets_file, scopes)\n",
    "            credentials = flow.run_console()\n",
    "\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(credentials, token)\n",
    "    return credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(video_Id,credentials,api_service_name,api_version,searchTerms):\n",
    "    \"\"\"è·å–è¯„è®ºï¼Œéœ€è¦ä¼ å…¥çš„å‚æ•°ï¼š/\n",
    "    video_Idï¼šYouTubeè§†é¢‘Idå·ï¼›credentials:è°·æ­Œapiè¯ä¹¦ï¼Œä»ä¸Šä¸€ä¸ªuse_credentials()è·å¾—/\n",
    "    api_service_nameï¼Œapi_versionä¼šåœ¨ä¸‹é¢çš„scraper()ä¸­å¾—åˆ°;\n",
    "    searchTermsï¼šç”¨äºç­›é€‰è¯„è®ºçš„å…³é”®è¯ï¼Œçˆ¬è™«ä¼šçˆ¬å–åŒ…å«è¿™äº›å…³é”®è¯çš„è¯„è®º\"\"\"\n",
    "    import googleapiclient.discovery\n",
    "    youtube = googleapiclient.discovery.build(api_service_name, api_version, credentials=credentials)\n",
    "    video_Id = video_Id\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet,replies\",\n",
    "        videoId=video_Id,\n",
    "        searchTerms=searchTerms,\n",
    "        maxResults = 100,\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    totalResults = 0\n",
    "    totalResults = int(response['pageInfo']['totalResults'])\n",
    "\n",
    "    count = 0\n",
    "    nextPageToken = ''\n",
    "    comments = []\n",
    "    first = True\n",
    "    further = True\n",
    "    while further:\n",
    "        halt = False\n",
    "        if first == False:\n",
    "            print('..')\n",
    "            try:\n",
    "                response = youtube.commentThreads().list(\n",
    "                    part=\"snippet,replies\",\n",
    "                    videoId=video_Id,\n",
    "                    searchTerms=searchTerms,\n",
    "                    maxResults = 100,\n",
    "                    textFormat='html',\n",
    "                    pageToken=nextPageToken\n",
    "                            ).execute()\n",
    "                totalResults = int(response['pageInfo']['totalResults'])\n",
    "            except HttpError as e:\n",
    "                print(\"An HTTP error %d occurred:\\n%s\" % (e.resp.status, e.content))\n",
    "                halt = True\n",
    "\n",
    "        if halt == False:\n",
    "            count += totalResults\n",
    "            for item in response[\"items\"]:\n",
    "                # è¿™åªæ˜¯ä¸€éƒ¨åˆ†æ•°æ®ï¼Œä½ éœ€è¦å•¥è‡ªå·±é€‰å°±è¡Œï¼Œå¯ä»¥å…ˆæ‰“å°ä¸‹ä½ èƒ½æ‹¿åˆ°é‚£äº›æ•°æ®ä¿¡æ¯ï¼ŒæŒ‰éœ€çˆ¬å–ã€‚\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"]\n",
    "                author = comment[\"snippet\"][\"authorDisplayName\"]\n",
    "                text = comment[\"snippet\"][\"textDisplay\"]\n",
    "                likeCount = comment[\"snippet\"]['likeCount']\n",
    "                publishtime = comment['snippet']['publishedAt']\n",
    "                comments.append([author, publishtime, likeCount, text,])\n",
    "\n",
    "            if totalResults < 100:\n",
    "                further = False\n",
    "                first = False\n",
    "            else:\n",
    "                further = True\n",
    "                first = False\n",
    "                try:\n",
    "                    nextPageToken = response[\"nextPageToken\"]\n",
    "                except KeyError as e:\n",
    "                    print(\"An KeyError error occurred: %s\" % (e))\n",
    "                    further = False\n",
    "    print('get comment count: ', str(count))\n",
    "    ### write to csv file\n",
    "    data = np.array(comments)\n",
    "    print('total comments and replies: ',data.shape[0])\n",
    "    df = pd.DataFrame(data, columns=['author', 'publishtime', 'likeCount', 'comment',])\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_format(df):\n",
    "    \"\"\"æ”¹å–„è¾“å‡ºçš„æ ¼å¼\"\"\"\n",
    "    df['comment']=df['comment'].str.replace('&#39;','\\'')\n",
    "    df['comment']=df['comment'].str.replace('<br />',' ')   \n",
    "    df['comment']=df['comment'].str.replace('&quot','\" ')     \n",
    "    df = df[df['comment'].str.len()<=50]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(videoId_list,searchTerms):\n",
    "    \"\"\"ä¼ å…¥youtubeè§†é¢‘idçš„åˆ—è¡¨ï¼Œå’Œç­›é€‰å…³é”®è¯çš„èŠè¡¨æ¥å®ç°å¾ªç¯æŠ“å–\"\"\"\n",
    "    #1.åˆå§‹åŒ–å˜é‡\n",
    "    scopes = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    client_secrets_file = \"client_secret.json\"    #è¿™ä¸ªjsonæ–‡ä»¶æ˜¯é€šè¿‡è°·æ­Œapiä¸‹è½½çš„    \n",
    "    credentials = None  \n",
    "    videoId_list = videoId_list\n",
    "    #2.å°†è°·æ­Œapiçš„å‡­æ®(credentials)è½¬æ¢ä¸ºpickleæ ¼å¼æ–‡ä»¶ï¼Œç„¶åä½¿ç”¨    \n",
    "    credentials = use_credentials(credentials,client_secrets_file)\n",
    "            \n",
    "    #3.\n",
    "    for video_id in videoId_list:\n",
    "        final_df = pd.DataFrame(columns=['author', 'publishtime', 'likeCount', 'comment'])\n",
    "        for term in searchTerms:\n",
    "            try:\n",
    "                df = pd.DataFrame(columns=['author', 'publishtime', 'likeCount', 'comment'])\n",
    "                df = get_comments(video_id,credentials,api_service_name,api_version,term)\n",
    "            except:\n",
    "                pass\n",
    "            #è¿™é‡Œéœ€è¦å¯¹dfè¿›è¡Œä¿®æ”¹\n",
    "            df = improve_format(df)            \n",
    "            final_df = final_df.append(df)\n",
    "        final_df.drop_duplicates(subset=['author', 'publishtime', 'likeCount', 'comment'],keep='first',inplace=True)       \n",
    "        output_filename = video_id+'_filter_searchTerms' +'_comments.csv'\n",
    "        final_df.to_csv(output_filename, index=0, encoding='utf_8_sig')#utf_8_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = ['Kzr9fq8Ig7I','u6T1jCemeRk','ITkVhQGJODE','uM0K8GN8tgY','uKkRzfTACyM','7HjNGv5e0Es','x7nd8He8APQ','Axe8sWXYFak']\n",
    "\n",
    "searchTerms = ['ğŸ˜¢','å“­','éš¾è¿‡','é›£é','ç—›å¿ƒ','ğŸ˜­','å¿ƒç—›','å‚·å¿ƒ','æ“”å¿ƒ','æ“”æ†‚','æ‹…å¿§','å®³æ€•','ææ‡¼','é©šæ','æ“”é©šå—æ€•','å“ˆå“ˆ','ğŸ˜¨','é«˜èˆˆ',\\\n",
    "               'é–‹å¿ƒ','æ†¤æ€’','ğŸ˜¡','åœè¡—','ç”Ÿæ°£','å¥½æ°£','æ°£æ†¤','å”‰','è¨å­','é„™è¦–']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scrap(video_list,searchTerms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
